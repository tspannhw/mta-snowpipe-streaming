# ğŸ”§ Deploy Script Updates for Kafka Integration

## âœ… What Was Updated

The deployment script (`deploy.sh`) has been enhanced to fully support the Kafka integration with comprehensive validation, testing, and monitoring capabilities.

### ğŸ¯ Key Updates Made

#### 1. **Enhanced Environment Validation**
- âœ… **Data Source Detection**: Automatically detects `DEFAULT_DATA_SOURCE` setting
- âœ… **Conditional Validation**: Different validation rules for Kafka vs MTA API
- âœ… **Kafka Authentication**: Validates SASL_SSL credentials and configuration
- âœ… **Smart Error Messages**: Specific guidance based on selected data source

#### 2. **Updated Environment Template**
```bash
# NEW: Kafka-first configuration template
DEFAULT_DATA_SOURCE=kafka
KAFKA_BOOTSTRAP_SERVERS=your-kafka-broker:9092
KAFKA_SASL_USERNAME=your_kafka_username
KAFKA_SASL_PASSWORD=your_kafka_password
KAFKA_TOPIC=icymta
```

#### 3. **New Kafka Testing Command**
```bash
# Test Kafka connectivity and authentication
./deploy.sh test-kafka
```

#### 4. **Enhanced Health Checks**
- âœ… **Kafka Status**: Includes Kafka integration health in service checks
- âœ… **Data Source Aware**: Health checks adapt based on configured data source
- âœ… **Consumer Monitoring**: Validates Kafka consumer connectivity

#### 5. **Improved User Experience**
- âœ… **Smart Guidance**: Shows data source-specific setup instructions
- âœ… **Deployment Info**: Displays active data source and Kafka topic info
- âœ… **Troubleshooting**: Built-in connection testing and error guidance

## ğŸš€ New Deployment Workflow

### 1. **Initial Setup** (Automatic template creation)
```bash
./deploy.sh setup
```
Creates `.env` file with Kafka-first configuration template.

### 2. **Configure Environment**
Edit `.env` file with your credentials:
```bash
# For Kafka (Primary)
DEFAULT_DATA_SOURCE=kafka
KAFKA_BOOTSTRAP_SERVERS=your-cluster:9092
KAFKA_SASL_USERNAME=your_username
KAFKA_SASL_PASSWORD=your_password

# For MTA API (Fallback) 
# DEFAULT_DATA_SOURCE=mta_api
# MTA_API_KEY=your_api_key
```

### 3. **Test Kafka Connection** (New Feature)
```bash
./deploy.sh test-kafka
```
Validates:
- âœ… Kafka broker connectivity
- âœ… SASL_SSL authentication
- âœ… Topic access and message consumption
- âœ… JSON parsing capabilities

### 4. **Deploy Stack**
```bash
./deploy.sh deploy
```
Now includes:
- âœ… Data source validation
- âœ… Kafka-specific environment checks
- âœ… Enhanced health monitoring
- âœ… Data source-aware status display

## ğŸ“‹ Enhanced Commands

### Environment Validation
The script now validates different variables based on data source:

**For Kafka Mode:**
- `KAFKA_BOOTSTRAP_SERVERS` âœ… Required
- `KAFKA_SASL_USERNAME` âœ… Required  
- `KAFKA_SASL_PASSWORD` âœ… Required
- `KAFKA_TOPIC` âœ… Optional (defaults to 'icymta')

**For MTA API Mode:**
- `MTA_API_KEY` âœ… Required

**Always Required:**
- `SNOWFLAKE_ACCOUNT`, `SNOWFLAKE_USER`, `SNOWFLAKE_PASSWORD` âœ…

### New Test Command
```bash
# Test Kafka connectivity
./deploy.sh test-kafka

# Expected output:
ğŸ”§ Testing Kafka Connection
Bootstrap servers: your-cluster:9092
Topic: icymta
Username: your_username
==================================================
âœ… Kafka consumer created successfully
âœ… Subscribed to topic: icymta
ğŸ“¡ Polling for messages (30 seconds)...
ğŸ“¨ Message 1:
   Topic: icymta
   Partition: 0
   Offset: 12345
   Sample fields: ['vehicleref', 'lineref', 'recordedattime']...
âœ… SUCCESS: Received 5 messages from Kafka
ğŸ‰ Kafka connection and authentication working correctly!
```

### Enhanced Status Display
```bash
./deploy.sh deploy
# Shows:
Data Source Configuration:
  â€¢ Primary Source:     kafka
  â€¢ Kafka Topic:        icymta  
  â€¢ Consumer Group:     snowpipe-streaming-consumer

Service Access URLs:
  â€¢ Application Health: http://localhost:8001/health
  â€¢ Test Kafka:         ./deploy.sh test-kafka
```

## ğŸ” Troubleshooting Integration

### Built-in Error Guidance
The script now provides specific troubleshooting steps:

**For Authentication Errors:**
```bash
âŒ Required Kafka variable KAFKA_SASL_USERNAME is not set in .env file
âŒ For Kafka data source, please configure all Kafka authentication variables
```

**For Connection Issues:**
```bash
âŒ Kafka connection test failed!

Troubleshooting steps:
  1. Verify Kafka credentials in .env file
  2. Check network connectivity to Kafka brokers  
  3. Ensure the icymta topic exists and has data
  4. Verify SASL/SSL configuration
```

### Validation Flow
```mermaid
graph TB
    A[./deploy.sh deploy] --> B[Check Prerequisites]
    B --> C[Load .env file]
    C --> D{Data Source?}
    D -->|kafka| E[Validate Kafka Vars]
    D -->|mta_api| F[Validate MTA API Vars]
    E --> G[Build & Deploy]
    F --> G
    G --> H[Health Checks]
    H --> I[Show Access Info]
```

## ğŸ“Š Benefits of Updated Script

### ğŸ¯ Intelligent Validation
- **Conditional Requirements**: Only validates variables needed for selected data source
- **Early Error Detection**: Catches configuration issues before deployment
- **Specific Guidance**: Tells users exactly what to configure

### ğŸ”§ Built-in Testing
- **Pre-deployment Testing**: Test Kafka before full deployment
- **Authentication Validation**: Verifies SASL_SSL credentials work
- **Topic Access Confirmation**: Ensures topic exists and is accessible

### ğŸ“± Better User Experience
- **Smart Defaults**: Kafka-first configuration with sensible defaults
- **Clear Instructions**: Step-by-step guidance based on data source
- **Status Awareness**: Shows what's actually configured and running

### ğŸ› ï¸ Operational Excellence
- **Comprehensive Health Checks**: Data source-aware monitoring
- **Troubleshooting Support**: Built-in diagnostic capabilities
- **Production Ready**: Robust error handling and validation

## ğŸ‰ Migration Complete!

The deploy script now provides enterprise-grade deployment automation for Kafka-integrated MTA data streaming with:

âœ… **Intelligent Configuration Management**  
âœ… **Built-in Kafka Testing and Validation**  
âœ… **Data Source-Aware Operations**  
âœ… **Comprehensive Error Guidance**  
âœ… **Production-Ready Deployment Flow**  

Your Kafka integration is now fully supported by a robust, user-friendly deployment pipeline!